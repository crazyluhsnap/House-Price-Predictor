# -*- coding: utf-8 -*-
"""House Price.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zWgwxAYnCczcm5uziVMWBn4Dw7U5dsoM

Importing the dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics
from sklearn.datasets import fetch_california_housing

"""Importing the Boston House Price dataset"""

house_price_dataset = fetch_california_housing(as_frame=True)
df = house_price_dataset.frame

print(house_price_dataset)

#Loading the dataset into pandas dataframe
house_price_dataframe=pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)

#printing first 5 rows
house_price_dataframe.head()

#add the target (price) column to the DataFrame
house_price_dataframe['Price'] = house_price_dataset.target

#printing first 5 rows
house_price_dataframe.head()

#checking the number of rows and columns in the dataframe
house_price_dataframe.shape

#checking for missing values
house_price_dataframe.isnull().sum()

#stastical measure of dataset
house_price_dataframe.describe()

"""Understanding the correlation between various features in the dataset"""

correlation = house_price_dataframe.corr()

#constructing a heatmap to understand the correlation between feauture
plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size':8}, cmap='Greens')

"""Splitting the data and target"""

X = house_price_dataframe.drop(['Price'], axis=1)
Y = house_price_dataframe['Price']

print(X)
print(Y)

"""Split the data into train and test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Training our model

XGBoost Regressor
"""

#loading the model
model=XGBRegressor()

#training the model with X_train
model.fit(X_train, Y_train)

"""Evaluating our model"""

#accuracy for prediction on training data
train_data_prediction = model.predict(X_train)

print(train_data_prediction)

#R squared error
score_1 = metrics.r2_score(Y_train, train_data_prediction)

#mean absolute error
score_2 = metrics.mean_absolute_error(Y_train, train_data_prediction)

print("R squared Error: ", score_1)
print("Mean absolute Error: ", score_2)

"""Visualizing the actual and predicted data"""

plt.scatter(Y_train, train_data_prediction)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Prices Vs Predicted Prices")
plt.show()

"""Prediction on test data"""

test_data_prediction=model.predict(X_test)

print(test_data_prediction)

#R squared error
score_3 = metrics.r2_score(Y_test, test_data_prediction)

#mean absolute error
score_4 = metrics.mean_absolute_error(Y_test, test_data_prediction)

print("R squared Error: ", score_3)
print("Mean absolute Error: ", score_4)

"""Visualizing the test data"""

plt.scatter(Y_test, test_data_prediction)
plt.xlabel("Actual test Prices")
plt.ylabel("Predicted test Prices")
plt.title("Actual Prices Vs Predicted Prices")
plt.show()

